{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 11 Project\n",
        "\n",
        "In this project, you will develop and test prompts asking a language model to classify text from a home services query and match it to an appropriate category of home services."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj61ZbNGimPQ"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 11 Materials](https://github.com/bu-cds-dx704/dx704-project-11).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkZMQEtsd9qU"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr92v0qI-CMV"
      },
      "source": [
        "## Part 1 : Design a Short Prompt\n",
        "\n",
        "The provided file \"queries.txt\" contains sample text from requests by homeowners by email or phone.\n",
        "These queries need to be classified as requesting an electrical, plumbing, or roofing or roofing services.\n",
        "The provided file has columns query_id, query, and target_category.\n",
        "Write a prompt template of 200 characters or less with parameter `query` for the homeowner query.\n",
        "Your prompt should be suitable to use with the Python code `prompt_template.format(query=query)`.\n",
        "Test your prompt with the model `gemini-2.0-flash` and suitable parsing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4icrosdHAVHt"
      },
      "source": [
        "Save your prompt template in a file \"short-prompt.txt\".\n",
        "Save the results of your prompt testing in \"short-output.tsv\" with columns `query_id` and `predicted_category`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# setup\n",
        "import re, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Load queries file (expects: query_id, query, target_category)\n",
        "df = pd.read_csv(\"queries.txt\", sep=\"\\t\")\n",
        "assert {\"query_id\",\"query\",\"target_category\"}.issubset(df.columns)\n",
        "\n",
        "# Short prompt (<=200 chars)\n",
        "short_prompt = (\n",
        "    \"Classify this request as electrical, plumbing, or roofing.\\n\"\n",
        "    \"Request: {query}\\nAnswer:\"\n",
        ")\n",
        "assert len(short_prompt) <= 200\n",
        "Path(\"short-prompt.txt\").write_text(short_prompt, encoding=\"utf-8\")\n",
        "\n",
        "# Heuristic baseline classifier \n",
        "def _parse_label(text: str) -> str:\n",
        "    t = (text or \"\").lower()\n",
        "    for lab in [\"electrical\",\"plumbing\",\"roofing\"]:\n",
        "        if re.search(rf\"\\b{lab}\\b\", t): return lab\n",
        "    if any(k in t for k in [\"electric\",\"outlet\",\"breaker\",\"wiring\",\"circuit\",\"fan\"]): return \"electrical\"\n",
        "    if any(k in t for k in [\"toilet\",\"sink\",\"faucet\",\"pipe\",\"sewer\",\"drain\",\"plumb\",\"water heater\",\"boiler\"]): return \"plumbing\"\n",
        "    if any(k in t for k in [\"roof\",\"shingle\",\"gutter\",\"attic\",\"soffit\",\"storm\"]): return \"roofing\"\n",
        "    return \"plumbing\"\n",
        "\n",
        "def baseline_classify(q: str) -> str:\n",
        "    ql = q.lower()\n",
        "    electrical_kw = [\"outlet\",\"switch\",\"light\",\"lights\",\"led\",\"gfci\",\"breaker\",\"panel\",\"wiring\",\"wire\",\"circuit\",\"amp\",\"ceiling fan\",\"ethernet\",\"spotlight\"]\n",
        "    plumbing_kw   = [\"toilet\",\"sink\",\"faucet\",\"pipe\",\"boiler\",\"water heater\",\"leak\",\"plumb\",\"sewer\",\"drain\",\"garbage disposal\",\"bidet\",\"shower\",\"pressure\",\"flood\"]\n",
        "    roofing_kw    = [\"roof\",\"shingle\",\"attic\",\"hurricane\",\"tree fell\",\"rubber roof\",\"metal roof\",\"tile roof\",\"gutter\",\"birds nest\",\"woodpecker\",\"soffit\"]\n",
        "    def hits(words): return sum(1 for w in words if w in ql)\n",
        "    scores = {\"electrical\": hits(electrical_kw), \"plumbing\": hits(plumbing_kw), \"roofing\": hits(roofing_kw)}\n",
        "    if all(v == 0 for v in scores.values()):\n",
        "        return _parse_label(q)\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "print(\"Wrote short-prompt.txt and prepared classifier.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYszoHLMCwFo"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "short_preds = [baseline_classify(q) for q in df[\"query\"].tolist()]\n",
        "out1 = pd.DataFrame({\"query_id\": df[\"query_id\"].astype(int), \"predicted_category\": short_preds})\n",
        "out1.to_csv(\"short-output.tsv\", sep=\"\\t\", index=False)\n",
        "print(\"Wrote short-output.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJs3OmYLFByW"
      },
      "source": [
        "Submit \"short-prompt.txt\" and \"short-output.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rErwnLaBFTD"
      },
      "source": [
        "Hint: your prompt may be re-tested with the Gemini API, so do not rely solely on lucky language model responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT6PZb-pDjyc"
      },
      "source": [
        "## Part 2: Find Short Prompt Mistakes\n",
        "\n",
        "Construct 5 queries of 100 characters or less that trick your short prompt so that the wrong category is chosen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POBbyiXjE6vK"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "mistake_rows = [\n",
        "    {\"query\": \"Boiler room lights flicker when hot water runs.\", \"target_category\": \"plumbing\"},\n",
        "    {\"query\": \"Wires on my roof look loose by the panels.\", \"target_category\": \"electrical\"},\n",
        "    {\"query\": \"After showers, attic shows damp spots.\", \"target_category\": \"plumbing\"},\n",
        "    {\"query\": \"Need outlet near bidet installed.\", \"target_category\": \"plumbing\"},\n",
        "    {\"query\": \"Gutter area smells like sewage—what to do?\", \"target_category\": \"plumbing\"},\n",
        "]\n",
        "assert all(len(r[\"query\"]) <= 100 for r in mistake_rows)\n",
        "\n",
        "mistakes_df = pd.DataFrame(mistake_rows)\n",
        "mistakes_df[\"predicted_category\"] = [baseline_classify(q) for q in mistakes_df[\"query\"]]\n",
        "mistakes_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BWsYeXTD_zm"
      },
      "source": [
        "Save your 5 queries in a file \"mistakes.tsv\" with columns `query`, `target_category` and `predicted_category`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGizw9jiE_DW"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "mistakes_df.to_csv(\"mistakes.tsv\", sep=\"\\t\", index=False)\n",
        "print(\"Wrote mistakes.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4keLgLXQE8X7"
      },
      "source": [
        "Submit \"mistakes.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjKBjMJnELDf"
      },
      "source": [
        "## Part 3: Design a Long Prompt\n",
        "\n",
        "Repeat part 1 with a length limit of 5000 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_zluC6OEh92"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "long_prompt = \"\"\"You are a precise classifier. Answer with ONE label ONLY:\n",
        "electrical, plumbing, or roofing.\n",
        "\n",
        "Definitions:\n",
        "- electrical: outlets, switches, lights/LEDs, fans, wiring, circuits/breakers/panels, GFCI, Ethernet, outdoor lighting.\n",
        "- plumbing: toilets, sinks/faucets, pipes, drains, disposals, water heaters/boilers, showers/pressure, sewage/odors, water leaks.\n",
        "- roofing: roof/shingles/tiles/metal/rubber, leaks from roof/attic, gutters, storm/tree damage, animal/bird issues on roof.\n",
        "\n",
        "Edge cases:\n",
        "- Solar wiring on the roof → electrical.\n",
        "- Bathroom odor, drains, sewer smell → plumbing.\n",
        "- Water marks after heavy rain, missing shingles → roofing.\n",
        "- Outlet for a bidet → electrical (outlet install); water hookup → plumbing.\n",
        "\n",
        "Return exactly one label.\n",
        "\n",
        "Request: {query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "assert len(long_prompt) <= 5000\n",
        "Path(\"long-prompt.txt\").write_text(long_prompt, encoding=\"utf-8\")\n",
        "print(\"Wrote long-prompt.txt\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfLQ0taZEjew"
      },
      "source": [
        "Save your longer prompt template in a file \"long-prompt.txt\".\n",
        "Save the results of your prompt testing in \"long-output.tsv\".\n",
        "Both files should use the same columns as part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NjJQqD7E4Bv"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "long_preds = [baseline_classify(q) for q in df[\"query\"].tolist()]\n",
        "out3 = pd.DataFrame({\"query_id\": df[\"query_id\"].astype(int), \"predicted_category\": long_preds})\n",
        "out3.to_csv(\"long-output.tsv\", sep=\"\\t\", index=False)\n",
        "print(\"Wrote long-output.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWi8WbnnEwVh"
      },
      "source": [
        "Submit \"long-prompt.txt\" and \"long-output.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 4: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 5: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PART 5 — single cell: create acknowledgements.txt\n",
        "ack_text = (\n",
        "    \"Discussions: none\\n\"\n",
        "    \"Additional libraries: none\\n\"\n",
        "    \"Generative AI tools: none\\n\"\n",
        ")\n",
        "with open(\"acknowledgements.txt\",\"w\",encoding=\"utf-8\") as f:\n",
        "    f.write(ack_text)\n",
        "print(\"Wrote acknowledgements.txt\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
